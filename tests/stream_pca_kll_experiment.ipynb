{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a149d6ffbf96f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T07:38:09.119405Z",
     "start_time": "2025-04-19T07:38:09.105927Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import tracemalloc\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    from datasketches import kll_floats_sketch\n",
    "except ImportError:\n",
    "    raise ImportError(\"Install with `pip install datasketches`\")\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "RESULTS_DIR = Path(\"stream_experiment_results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# Utilities\n",
    "def current_mem_rss():\n",
    "    return psutil.Process().memory_info().rss\n",
    "\n",
    "\n",
    "def sketch_serialized_size(sketch: kll_floats_sketch):\n",
    "    return len(sketch.serialize())\n",
    "\n",
    "\n",
    "def generate_stream(\n",
    "    n_samples, n_features, batch_size, distribution=\"normal\", variance=1.0, seed=42\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_batches = int(np.ceil(n_samples / batch_size))\n",
    "    for _ in range(n_batches):\n",
    "        if distribution == \"normal\":\n",
    "            batch = rng.normal(0.0, variance, size=(batch_size, n_features))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported distribution: {distribution}\")\n",
    "        yield batch.astype(np.float32)\n",
    "\n",
    "\n",
    "def pca_reconstruction_mse(pca_obj, X):\n",
    "    try:\n",
    "        comps = pca_obj.transform(X)\n",
    "        recon = pca_obj.inverse_transform(comps)\n",
    "        return float(np.mean((X - recon) ** 2))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def kll_median_error(sketches, X):\n",
    "    errs = []\n",
    "    for j, s in enumerate(sketches):\n",
    "        approx = s.get_quantile(0.5)\n",
    "        truth = np.median(X[:, j])\n",
    "        errs.append(abs(truth - approx))\n",
    "    return float(np.mean(errs))\n",
    "\n",
    "\n",
    "# Inserted imports and setup (same as before)\n",
    "\n",
    "\n",
    "def run_config(\n",
    "    n_samples,\n",
    "    n_features,\n",
    "    batch_size,\n",
    "    kll_k,\n",
    "    n_components,\n",
    "    seed,\n",
    "    compute_accuracy=False,\n",
    "    mode=\"both\",\n",
    "):\n",
    "    tracemalloc.start()\n",
    "    gc.collect()\n",
    "\n",
    "    stream = generate_stream(n_samples, n_features, batch_size, seed=seed)\n",
    "    rss_baseline = current_mem_rss()\n",
    "\n",
    "    ipca = (\n",
    "        IncrementalPCA(n_components=n_components) if mode in [\"both\", \"pca\"] else None\n",
    "    )\n",
    "    sketches = (\n",
    "        [kll_floats_sketch(kll_k) for _ in range(n_features)]\n",
    "        if mode in [\"both\", \"kll\"]\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    holdout = (\n",
    "        np.vstack(\n",
    "            [next(generate_stream(5000, n_features, 1000, seed=999)) for _ in range(5)]\n",
    "        )\n",
    "        if compute_accuracy\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    metrics = []\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for i, batch in enumerate(stream, 1):\n",
    "        t_data = 0.0\n",
    "\n",
    "        # PCA\n",
    "        if mode in [\"both\", \"pca\"]:\n",
    "            t0 = time.perf_counter()\n",
    "            ipca.partial_fit(batch)\n",
    "            t_ipca = time.perf_counter() - t0\n",
    "            ipca_mem = current_mem_rss() - rss_baseline\n",
    "        else:\n",
    "            t_ipca = 0.0\n",
    "            ipca_mem = 0.0\n",
    "\n",
    "        # KLL\n",
    "        if mode in [\"both\", \"kll\"]:\n",
    "            t0 = time.perf_counter()\n",
    "            for j in range(n_features):\n",
    "                sketches[j].update(batch[:, j])\n",
    "            t_kll = time.perf_counter() - t0\n",
    "            kll_mem = current_mem_rss() - rss_baseline\n",
    "        else:\n",
    "            t_kll = 0.0\n",
    "            kll_mem = 0.0\n",
    "\n",
    "        pca_mse = (\n",
    "            pca_reconstruction_mse(ipca, holdout)\n",
    "            if compute_accuracy and ipca and i % 5 == 0\n",
    "            else np.nan\n",
    "        )\n",
    "        kll_err = (\n",
    "            kll_median_error(sketches, batch)\n",
    "            if compute_accuracy and sketches\n",
    "            else np.nan\n",
    "        )\n",
    "\n",
    "        metrics.append(\n",
    "            {\n",
    "                \"batch\": i,\n",
    "                \"t_data\": t_data,\n",
    "                \"t_ipca\": t_ipca,\n",
    "                \"t_kll\": t_kll,\n",
    "                \"throughput_sps\": batch_size / (t_ipca + t_kll),\n",
    "                \"ipca_mem_delta\": ipca_mem,\n",
    "                \"kll_mem_delta\": kll_mem,\n",
    "                \"pca_mse\": pca_mse,\n",
    "                \"kll_median_err\": kll_err,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    total_time = time.perf_counter() - start_time\n",
    "    _, peak_rss = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    kll_serialized_size = (\n",
    "        sum(sketch_serialized_size(s) for s in sketches) if sketches else 0\n",
    "    )\n",
    "\n",
    "    full_df = pd.DataFrame(metrics)\n",
    "    summary = {\n",
    "        \"mode\": mode,\n",
    "        \"kll_k\": kll_k,\n",
    "        \"n_components\": n_components,\n",
    "        \"seed\": seed,\n",
    "        \"total_time_s\": total_time,\n",
    "        \"peak_rss_bytes\": peak_rss,\n",
    "        \"mean_pca_mse\": full_df[\"pca_mse\"].mean(),\n",
    "        \"mean_kll_err\": full_df[\"kll_median_err\"].mean(),\n",
    "        \"n_samples\": n_samples,\n",
    "        \"n_features\": n_features,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"kll_serialized_size_bytes\": kll_serialized_size,\n",
    "    }\n",
    "\n",
    "    return summary, full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a432a08f558918b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T07:41:29.322480Z",
     "start_time": "2025-04-19T07:38:09.139449Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [02:12<00:00,  1.22s/it]\n",
      "100%|██████████| 108/108 [01:07<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run Grid\n",
    "n_samples = 100_000\n",
    "n_features = 100\n",
    "batch_size = 1000\n",
    "kll_ks = [8, 16, 32, 64, 128, 200]\n",
    "n_comps = [2, 5, 10, 20, 50, 100]\n",
    "seeds = [42, 101, 202]\n",
    "\n",
    "# Run Grid: separate PCA and KLL experiments\n",
    "grid_results = []\n",
    "batch_metrics = []\n",
    "\n",
    "for mode in [\"pca\", \"kll\"]:\n",
    "    for kll_k, n_comp, seed in tqdm(\n",
    "        product(kll_ks, n_comps, seeds), total=len(kll_ks) * len(n_comps) * len(seeds)\n",
    "    ):\n",
    "        summary, batch_df = run_config(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_features,\n",
    "            batch_size=batch_size,\n",
    "            kll_k=kll_k,\n",
    "            n_components=n_comp,\n",
    "            seed=seed,\n",
    "            compute_accuracy=True,\n",
    "            mode=mode,\n",
    "        )\n",
    "        batch_df[\"mode\"] = mode\n",
    "        batch_df[\"kll_k\"] = kll_k\n",
    "        batch_df[\"n_components\"] = n_comp\n",
    "        batch_df[\"seed\"] = seed\n",
    "\n",
    "        grid_results.append(summary)\n",
    "        batch_metrics.append(batch_df)\n",
    "\n",
    "# Save results\n",
    "summary_df = pd.DataFrame(grid_results)\n",
    "batch_df = pd.concat(batch_metrics, ignore_index=True)\n",
    "\n",
    "summary_df.to_csv(RESULTS_DIR / \"summary_metrics_split.csv\", index=False)\n",
    "batch_df.to_csv(RESULTS_DIR / \"all_batch_metrics_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8c623c50d18eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T07:41:29.366071Z",
     "start_time": "2025-04-19T07:41:29.334250Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/driftwatch-new/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time_mean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# summary_df = pd.read_csv(\"path/to/summary_metrics_split.csv\")\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m latex_code \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_latex_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(latex_code)\n",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m, in \u001b[0;36mgenerate_latex_table\u001b[0;34m(summary_df)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_, pca_row), (_, kll_row) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pca_df\u001b[38;5;241m.\u001b[39miterrows(), kll_df\u001b[38;5;241m.\u001b[39miterrows()):\n\u001b[1;32m     25\u001b[0m     pca_comp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(pca_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m     pca_time \u001b[38;5;241m=\u001b[39m format_value(\u001b[43mpca_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime_mean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, pca_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_std\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m     pca_mem \u001b[38;5;241m=\u001b[39m format_value(pca_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m], pca_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_std\u001b[39m\u001b[38;5;124m\"\u001b[39m], is_sci\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m     kll_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(kll_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkll_k\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/driftwatch-new/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/envs/driftwatch-new/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/driftwatch-new/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time_mean'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
